import os
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
from pykrx import stock

try:
    import FinanceDataReader as fdr
    HAS_FDR = True
except Exception:
    HAS_FDR = False


CFG = {
    "w_roe": 0.40,
    "w_div": 0.30,
    "w_per": 0.15,
    "w_pbr": 0.15,
    "market": "KOSPI",
    "top_n_div": 100,
    "report_top": 20,
    "apply_sector_adjust": True,
    "include_reits": True,
    "include_financials": True,
    "exclude_pref_spac": True,
    "min_trading_value_krw": 5e8,
}


# -----------------------------------------------------------
# ğŸ“Œ ìˆ˜ì •ëœ í•µì‹¬ í•¨ìˆ˜ (ë¬¸ì œ í•´ê²°)
# -----------------------------------------------------------

def pct_rank(s: pd.Series, higher=True) -> pd.Series:
    """
    0~100 ë°±ë¶„ìœ„ ì ìˆ˜ ê³„ì‚°
    higher=True â†’ ê°’ì´ í´ìˆ˜ë¡ 100ì (ì¢‹ìŒ)
    higher=False â†’ ê°’ì´ ì‘ì„ìˆ˜ë¡ 100ì (ì¢‹ìŒ)
    """
    s = s.copy()
    na_mask = s.isna()

    # ascending=True â†’ ê°’ì´ ì‘ìœ¼ë©´ ë‚®ì€ pct, í¬ë©´ ë†’ì€ pct
    pct = s.rank(pct=True, ascending=True)

    if higher:
        res = pct * 100
    else:
        res = (1 - pct) * 100

    res[na_mask] = np.nan
    return res.clip(0, 100)


# -----------------------------------------------------------
# ìœ í‹¸
# -----------------------------------------------------------

def get_latest_bday(max_lookback_days=10, market="KOSPI"):
    today = datetime.today().date()
    for i in range(max_lookback_days):
        d = (today - timedelta(days=i)).strftime("%Y%m%d")
        try:
            df = stock.get_market_fundamental_by_ticker(d, market=market)
            if isinstance(df, pd.DataFrame) and len(df) > 0:
                return d
        except Exception:
            pass
    raise RuntimeError("ê¸°ì¤€ì¼ íƒìƒ‰ ì‹¤íŒ¨")


def safe_sector_dataframe():
    if not HAS_FDR:
        return None
    try:
        krx_list = fdr.StockListing("KRX")

        rename_map = {"Symbol": "ticker", "Name": "fdr_name"}
        for k, v in rename_map.items():
            if k in krx_list.columns:
                krx_list = krx_list.rename(columns={k: v})

        krx_list["ticker"] = krx_list["ticker"].astype(str).str.zfill(6)

        for col in ["Sector", "Industry", "Market"]:
            if col not in krx_list.columns:
                krx_list[col] = np.nan

        return krx_list.set_index("ticker")[["fdr_name", "Sector", "Industry", "Market"]]
    except Exception:
        return None


def choose_sector(row):
    for col in ["Sector", "Industry", "Market"]:
        val = row.get(col, None)
        if isinstance(val, str) and val:
            return val
    return "ê¸°íƒ€"


# -----------------------------------------------------------
# ğŸ“Œ ë³¸ í•¨ìˆ˜: ë°°ë‹¹+ê°€ì¹˜ ì ìˆ˜ ê³„ì‚°
# -----------------------------------------------------------

def get_dividend_ranking():

    BASE_DATE = get_latest_bday(market=CFG["market"])

    # 1) ê¸°ë³¸ ì¬ë¬´
    fund = stock.get_market_fundamental_by_ticker(BASE_DATE, market=CFG["market"]).copy()
    need_cols = ["PER", "PBR", "EPS", "BPS", "DPS", "DIV"]
    for col in need_cols:
        if col not in fund.columns:
            fund[col] = np.nan

    fund = fund.replace([np.inf, -np.inf], np.nan)
    fund["DPS"] = fund["DPS"].fillna(0)
    fund["EPS"] = fund["EPS"].fillna(0)

    # 2) ì‹œì´ / ê±°ë˜ëŒ€ê¸ˆ
    cap = stock.get_market_cap_by_ticker(BASE_DATE, market=CFG["market"]).copy()
    if "ê±°ë˜ëŒ€ê¸ˆ" not in cap.columns:
        cap["ê±°ë˜ëŒ€ê¸ˆ"] = np.nan

    if "ìƒì¥ì£¼ì‹ìˆ˜" in cap.columns:
        df = fund.join(cap[["ê±°ë˜ëŒ€ê¸ˆ", "ìƒì¥ì£¼ì‹ìˆ˜"]], how="left")
    else:
        df = fund.join(cap[["ê±°ë˜ëŒ€ê¸ˆ"]], how="left")

    # 3) ì¢…ëª©ëª… / ì„¹í„°
    tickers = df.index.tolist()
    name_map = {t: stock.get_market_ticker_name(t) for t in tickers}
    df["name"] = df.index.map(name_map.get)

    meta = safe_sector_dataframe()
    if meta is not None:
        df = df.join(meta, how="left")
    else:
        df["Sector"] = np.nan

    df["Sector"] = df.apply(choose_sector, axis=1)

    # 4) í•„í„°ë§
    if CFG["exclude_pref_spac"]:
        name_series = df["name"].fillna("")
        df = df[~name_series.str.endswith("ìš°")]
        df = df[~name_series.str.contains("ìš°ì„ |ìŠ¤íŒ©|SPAC")]

    if not CFG["include_reits"]:
        df = df[~df.apply(lambda r: "ë¦¬ì¸ " in (r["name"] or "") or "REIT" in (r["Sector"] or ""), axis=1)]

    if not CFG["include_financials"]:
        df = df[~df["Sector"].fillna("").apply(lambda x: any(k in x for k in ["ì€í–‰", "ì¦ê¶Œ", "ë³´í—˜", "ì§€ì£¼", "ê¸ˆìœµ"]))]

    df = df[df["ê±°ë˜ëŒ€ê¸ˆ"].fillna(0) >= CFG["min_trading_value_krw"]].copy()

    # 5) ROE ê·¼ì‚¬
    df["ROE_est"] = np.where((df["BPS"] > 0) & df["EPS"].notna(), df["EPS"] / df["BPS"], np.nan)

    # 6) ë°°ë‹¹ìƒìœ„ N
    df_top = df.sort_values("DIV", ascending=False).head(CFG["top_n_div"]).copy()
    df_top["fcf_coverage"] = np.nan

    # 7) ë°±ë¶„ìœ„ ì ìˆ˜ ê³„ì‚° (ì „ì²´)
    df_top["div_pct_all"] = pct_rank(df_top["DIV"], True)
    df_top["roe_pct_all"] = pct_rank(df_top["ROE_est"], True)
    df_top["per_pct_all"] = pct_rank(df_top["PER"], False)
    df_top["pbr_pct_all"] = pct_rank(df_top["PBR"], False)

    # 8) ì„¹í„° ì¡°ì •
    if CFG["apply_sector_adjust"]:

        def grp_pct(col, higher=True):
            return df_top.groupby("Sector")[col].transform(lambda s: pct_rank(s, higher=higher))

        df_top["div_pct"] = grp_pct("DIV", True)
        df_top["roe_pct"] = grp_pct("ROE_est", True)
        df_top["per_pct"] = grp_pct("PER", False)
        df_top["pbr_pct"] = grp_pct("PBR", False)

        # ì„¹í„° ë‚´ ì¢…ëª©ìˆ˜ ì ìœ¼ë©´ ì „ì²´ ë­í‚¹ ì‚¬ìš©
        grp_size = df_top.groupby("Sector")["name"].transform("size")
        small_grp = grp_size < 3
        for c_pair in [
            ("div_pct", "div_pct_all"),
            ("roe_pct", "roe_pct_all"),
            ("per_pct", "per_pct_all"),
            ("pbr_pct", "pbr_pct_all"),
        ]:
            df_top.loc[small_grp, c_pair[0]] = df_top.loc[small_grp, c_pair[1]]
    else:
        df_top["div_pct"] = df_top["div_pct_all"]
        df_top["roe_pct"] = df_top["roe_pct_all"]
        df_top["per_pct"] = df_top["per_pct_all"]
        df_top["pbr_pct"] = df_top["pbr_pct_all"]

    # 9) ìµœì¢… ì ìˆ˜
    df_top["base_score"] = (
        CFG["w_roe"] * df_top["roe_pct"] +
        CFG["w_div"] * df_top["div_pct"] +
        CFG["w_per"] * df_top["per_pct"] +
        CFG["w_pbr"] * df_top["pbr_pct"]
    )

    df_top["score"] = df_top["base_score"]

    # PER, PBR ì´ìƒì¹˜ ì œê±°
    df_top = df_top[df_top["PER"] > 0]
    df_top = df_top[df_top["PBR"] > 0]

    # í‹°ì»¤ ì •ë¦¬
    df_top["ticker"] = df_top.index.astype(str).str.zfill(6)

    ranked = df_top.sort_values("score", ascending=False).reset_index(drop=True)
    ranked["score"] = ranked["score"].round(2)

    TOP_N = int(CFG["report_top"])
    disp_cols = ["ticker", "name", "score", "DIV", "ROE_est", "PER", "PBR", "Sector"]
    disp_cols = [c for c in disp_cols if c in ranked.columns]

    return BASE_DATE, ranked[disp_cols].head(TOP_N)

# ================================
# âœ… API í˜¸ì¶œìš© ë˜í¼ í•¨ìˆ˜ (views.pyê°€ ì´ê±¸ ë¶€ë¦„)
# ================================
from typing import Dict, List, Optional

def get_stock_ranking(limit: Optional[int] = None) -> Dict[str, object]:
    """
    1. get_dividend_ranking()ì„ ì‹¤í–‰í•´ì„œ ë¶„ì„ ë°ì´í„°ë¥¼ ë°›ì•„ì˜´.
    2. JSONìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥í•œ í˜•íƒœ(List of Dict)ë¡œ ë°”ê¿ˆ.
    3. ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì•ˆì „í•˜ê²Œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë‚˜ ë”ë¯¸ ë°ì´í„°ë¥¼ ë°˜í™˜.
    """
    print("ğŸ¢ [utils.py] ì£¼ì‹ ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    try:
        # ìœ„ì—ì„œ ì •ì˜ëœ ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œ
        base_date, df = get_dividend_ranking()
        
        # ğŸš¨ ë°ì´í„°ê°€ 0ê°œì¼ ê²½ìš° (ì¥ ì‹œì‘ ì „, íœ´ì¼ ë“±) -> ë°©ì–´ ë¡œì§
        if df is None or df.empty:
            print("ğŸš¨ [Alert] ë¶„ì„ëœ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„°ë§ ì¡°ê±´ì´ ë„ˆë¬´ ì—„ê²©í•˜ê±°ë‚˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨)")
            # í™”ë©´ì´ í„°ì§€ì§€ ì•Šê²Œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ë˜ëŠ” ì—¬ê¸°ì„œ ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì„ ìˆ˜ë„ ìˆìŒ)
            return {"base_date": base_date, "rows": []}

        # ê°œìˆ˜ ì œí•œ
        if limit:
            df = df.head(limit)

        # ğŸš¨ [ì¤‘ìš”] JSON ë³€í™˜ ì—ëŸ¬ ë°©ì§€ (NaN, Infinity ì œê±°)
        df = df.replace([np.inf, -np.inf], np.nan)
        df = df.fillna(0) # ë¹„ì–´ìˆëŠ” ê°’ì€ 0ìœ¼ë¡œ ì±„ì›€
        
        # DataFrame -> ë¦¬ìŠ¤íŠ¸ ë³€í™˜ (rows)
        # ë°±ì—”ë“œ ë³€ìˆ˜ëª…(ticker)ê³¼ í”„ë¡ íŠ¸ì—”ë“œ ë³€ìˆ˜ëª…(ticker)ì´ ì¼ì¹˜í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë³€í™˜
        rows = df.to_dict(orient="records")
        
        print(f"âœ… [Success] {len(rows)}ê°œ ì¢…ëª© ë¶„ì„ ì™„ë£Œ!")
        
        return {
            "base_date": base_date,
            "rows": rows,
        }

    except Exception as e:
        print(f"ğŸ”¥ [Error] utils.py ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì—ëŸ¬ê°€ ë‚˜ë„ ì„œë²„ê°€ ë©ˆì¶”ì§€ ì•Šê²Œ ë¹ˆ ê°’ ë°˜í™˜
        return {"base_date": datetime.today().strftime("%Y%m%d"), "rows": []}